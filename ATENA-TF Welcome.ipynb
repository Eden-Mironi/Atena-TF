{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ATENA-TensorFlow Welcome!\n",
    "\n",
    "Welcome to ATENA-TF - the TensorFlow implementation of ATENA for interactive data analysis!\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Environment setup and properties\n",
    "- Random agent exploration \n",
    "- Custom action sequences\n",
    "- Flight dataset analysis\n",
    "- Reward system components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded with:\n",
      "  - humanity_coeff: 1.0\n",
      "  - diversity_coeff: 2.0\n",
      "  - kl_coeff: 1.5\n",
      "  - compaction_coeff: 2.0\n",
      "  - adam_lr: 0.0003\n",
      "  - ppo_gamma: 0.995\n",
      "  - ppo_lambda: 0.97\n",
      "Registering ATENAcont-v0 environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded with:\n",
      "  - humanity_coeff: 1.0\n",
      "  - diversity_coeff: 2.0\n",
      "  - kl_coeff: 1.5\n",
      "  - compaction_coeff: 2.0\n",
      "  - adam_lr: 0.0003\n",
      "  - ppo_gamma: 0.995\n",
      "  - ppo_lambda: 0.97\n",
      "âœ… Using Snorkel compatibility adapter\n",
      "âœ… REWARD STABILIZER: DISABLED (stable mode like train_ipdate-1009-18:54.png)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ ATENA-TF loaded successfully!\n",
      "ðŸ“Š Schema: NETWORKING\n",
      "ðŸŽ¯ Max steps: 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add paths\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir, 'Configuration'))\n",
    "sys.path.append(os.path.join(current_dir, 'gym_atena/envs'))\n",
    "sys.path.append(os.path.join(current_dir, 'models/ppo'))\n",
    "\n",
    "# Import ATENA components\n",
    "import config as cfg\n",
    "from gym_atena.envs.enhanced_atena_env import make_enhanced_atena_env\n",
    "from models.ppo.agent import PPOAgent\n",
    "\n",
    "print(\" ATENA-TF loaded successfully!\")\n",
    "print(f\" Schema: {cfg.schema}\")\n",
    "print(f\" Max steps: {cfg.MAX_NUM_OF_STEPS}\")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading datasets for schema: NETWORKING\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/Users/edenmironi/Desktop/school/third year/Atena/ATENA-A-EDA/Compare/atena-tf 2/gym_atena/envs/atena_snorkel/snorkel_compatibility.py:122: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  return super().find_class(module, name)\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Datasets loaded successfully!\n",
      "ðŸ”§ Fixing old snorkel.learning references in checkpoint...\n",
      "âœ… Successfully loaded Snorkel checkpoint with compatibility fixes\n",
      "ðŸ”§ Initializing real LabelModel with checkpoint data...\n",
      "   Fitting LabelModel with dummy data: L_train(100, 51), class_balance=[0.5, 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[0 epochs]: TRAIN:[loss=96.139]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=36.231]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=12.033]\n",
      "INFO:root:[30 epochs]: TRAIN:[loss=5.283]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=5.784]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=5.441]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=4.885]\n",
      "INFO:root:[70 epochs]: TRAIN:[loss=4.801]\n",
      "INFO:root:[80 epochs]: TRAIN:[loss=4.789]\n",
      "INFO:root:[90 epochs]: TRAIN:[loss=4.774]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Real LabelModel initialized and ready for predictions!\n",
      "âœ… Loaded Snorkel model from snorkel_checkpoints\n",
      "Enhanced ATENA Environment initialized with:\n",
      "  - Rule-based humanity scoring: âœ“\n",
      "  - Enhanced diversity rewards: âœ“\n",
      "  - Detailed reward tracking: âœ“\n",
      "  - Max steps: 12\n",
      "âœ… Environment created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create ATENA environment\n",
    "env = make_enhanced_atena_env(max_steps=cfg.MAX_NUM_OF_STEPS)\n",
    "print(\" Environment created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Environment Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” ENVIRONMENT PROPERTIES:\n",
      "========================================\n",
      "Action space size: Box(-3.0, 3.0, (6,), float32)\n",
      "Action space low: [-3. -3. -3. -3. -3. -3.]\n",
      "Action space high: [3. 3. 3. 3. 3. 3.]\n",
      "Observation space: Box([ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 1. 1.], (51,), float32)\n",
      "Observation space low: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "Observation space high: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]...\n",
      "Reward range: (-inf, inf)\n"
     ]
    }
   ],
   "source": [
    "print(\" ENVIRONMENT PROPERTIES:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Action space size: {env.action_space}\")\n",
    "print(f\"Action space low: {env.action_space.low}\")\n",
    "print(f\"Action space high: {env.action_space.high}\")\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"Observation space low: {env.observation_space.low[:10]}...\")  # Show first 10\n",
    "print(f\"Observation space high: {env.observation_space.high[:10]}...\")\n",
    "print(f\"Reward range: {env.reward_range}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ² Environment Reset and Initial State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Environment reset!\n",
      "ðŸ“Š Initial observation shape: (51,)\n",
      "ðŸ“Š Initial observation (first 10 values): [1.0000000e+00 0.0000000e+00 1.0000000e+00 2.3126735e-04 0.0000000e+00\n",
      " 3.4415670e-02 2.3126735e-04 0.0000000e+00 3.4415670e-02 3.4690101e-04]\n",
      "ðŸ“‹ Dataset loaded: 8648 records\n",
      "ðŸ“‹ Columns: ['packet_number', 'eth_dst', 'eth_src', 'highest_layer', 'info_line', 'ip_dst', 'ip_src', 'length', 'sniff_timestamp', 'tcp_dstport', 'tcp_srcport', 'tcp_stream']\n"
     ]
    }
   ],
   "source": [
    "# Reset environment and get initial observation\n",
    "initial_obs = env.reset()\n",
    "\n",
    "print(\" Environment reset!\")\n",
    "print(f\" Initial observation shape: {initial_obs.shape}\")\n",
    "print(f\" Initial observation (first 10 values): {initial_obs[:10]}\")\n",
    "\n",
    "if hasattr(env, 'data') and env.data is not None:\n",
    "    print(f\"ðŸ“‹ Dataset loaded: {len(env.data)} records\")\n",
    "    if hasattr(env.data, 'columns'):\n",
    "        print(f\"ðŸ“‹ Columns: {list(env.data.columns)}\")\n",
    "else:\n",
    "    print(\"ðŸ“‹ Dataset: Ready for analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Action Types and Meanings\n",
    "\n",
    "ATENA supports 3 main action types:\n",
    "- **0 = Back**: Return to previous view\n",
    "- **1 = Filter**: Filter data by column values\n",
    "- **2 = Group**: Group data by column and aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ EXAMPLE ACTIONS:\n",
      "1. [0, 0, 0, 0, 0, 0] â†’ ðŸ”™ Go back to previous view\n",
      "2. [1, 2, 0, 0, 0, 0] â†’ ðŸ” Filter data by 'eth_dst'\n",
      "3. [2, 5, 0, 0, 0, 0] â†’ ðŸ“Š Group data by 'tcp_srcport'\n"
     ]
    }
   ],
   "source": [
    "def action_to_description(action):\n",
    "    \"\"\"Convert action vector to human-readable description\"\"\"\n",
    "    if len(action) < 2:\n",
    "        return \"Invalid action\"\n",
    "    \n",
    "    action_type = int(action[0])\n",
    "    action_param = int(action[1]) if len(action) > 1 else 0\n",
    "    \n",
    "    # Column mappings for different schemas\n",
    "    if cfg.schema == 'FLIGHTS':\n",
    "        columns = [\n",
    "            \"scheduled_departure\", \"departure_delay\", \"arrival_delay\", \"distance\", \n",
    "            \"scheduled_arrival\", \"departure_time\", \"arrival_time\", \"origin_airport\",\n",
    "            \"destination_airport\", \"airline\", \"flight_number\", \"aircraft\", \"flight_date\"\n",
    "        ]\n",
    "    else:\n",
    "        columns = [\n",
    "            \"packet_number\", \"eth_src\", \"eth_dst\", \"ip_src\", \"ip_dst\", \n",
    "            \"tcp_srcport\", \"tcp_dstport\", \"highest_layer\", \"info_line\"\n",
    "        ]\n",
    "    \n",
    "    column_name = columns[action_param] if action_param < len(columns) else f\"column_{action_param}\"\n",
    "    \n",
    "    if action_type == 0:\n",
    "        return \"ðŸ”™ Go back to previous view\"\n",
    "    elif action_type == 1:\n",
    "        return f\" Filter data by '{column_name}'\"\n",
    "    elif action_type == 2:\n",
    "        return f\" Group data by '{column_name}'\"\n",
    "    else:\n",
    "        return f\"â“ Unknown action (type={action_type}, param={action_param})\"\n",
    "\n",
    "# Example actions\n",
    "example_actions = [\n",
    "    [0, 0, 0, 0, 0, 0],  # Back\n",
    "    [1, 2, 0, 0, 0, 0],  # Filter by column 2\n",
    "    [2, 5, 0, 0, 0, 0],  # Group by column 5\n",
    "]\n",
    "\n",
    "print(\" EXAMPLE ACTIONS:\")\n",
    "for i, action in enumerate(example_actions):\n",
    "    print(f\"{i+1}. {action} â†’ {action_to_description(action)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Random Agent Demonstration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² RUNNING RANDOM EPISODE:\n",
      "==================================================\n",
      "Warning: Invalid action[0]=3, defaulting to 'back' action\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Step 1: ðŸ“Š Group data by 'eth_dst'\n",
      "         â†’ Reward: 0.000\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: 0.00\n",
      "\n",
      "Warning: Invalid action[0]=3, defaulting to 'back' action\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸŽ¯ Snorkel humanity: -0.999108\n",
      "Step 2: ðŸ“Š Group data by 'highest_layer'\n",
      "         â†’ Reward: -1.598\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: -0.80\n",
      "\n",
      "Warning: Invalid action[0]=-2, defaulting to 'back' action\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Step 3: â“ Unknown action (type=-1, param=1)\n",
      "         â†’ Reward: 0.400\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: 0.20\n",
      "\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸŽ¯ Snorkel humanity: -0.999108\n",
      "Step 4: ðŸ”™ Go back to previous view\n",
      "         â†’ Reward: -1.598\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: -0.80\n",
      "\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Step 5: ðŸ”™ Go back to previous view\n",
      "         â†’ Reward: 0.400\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: 0.20\n",
      "\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸŽ¯ Snorkel humanity: -0.999108\n",
      "Step 6: ðŸ”™ Go back to previous view\n",
      "         â†’ Reward: -1.598\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: -0.80\n",
      "\n",
      "Warning: Invalid action[0]=-2, defaulting to 'back' action\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Step 7: â“ Unknown action (type=-1, param=-1)\n",
      "         â†’ Reward: 0.400\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: 0.20\n",
      "\n",
      "Warning: Invalid action[0]=-2, defaulting to 'back' action\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.999108\n",
      "ðŸŽ¯ Snorkel humanity: -0.999108\n",
      "Step 8: â“ Unknown action (type=-2, param=0)\n",
      "         â†’ Reward: -1.598\n",
      "         â†’ Components: diversity: 0.00, interestingness: 0.00, humanity: -0.80\n",
      "\n",
      "ðŸ Total reward: -5.193\n",
      "ðŸ“Š Average reward per step: -0.649\n"
     ]
    }
   ],
   "source": [
    "def run_random_episode(env, max_steps=5, verbose=True):\n",
    "    \"\"\"Run an episode with random actions\"\"\"\n",
    "    \n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    actions_taken = []\n",
    "    rewards_received = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"ðŸŽ² RUNNING RANDOM EPISODE:\")\n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # Sample random action from action space\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        # Take the action\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        actions_taken.append(action)\n",
    "        rewards_received.append(reward)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Step {step+1}: {action_to_description(action)}\")\n",
    "            print(f\"         â†’ Reward: {reward:.3f}\")\n",
    "            \n",
    "            # Show reward components if available\n",
    "            if 'reward_info' in info:\n",
    "                components = info['reward_info']\n",
    "                main_components = ['diversity', 'interestingness', 'humanity']\n",
    "                comp_str = \", \".join([f\"{k}: {v:.2f}\" for k, v in components.items() \n",
    "                                    if k in main_components and isinstance(v, (int, float))])\n",
    "                if comp_str:\n",
    "                    print(f\"         â†’ Components: {comp_str}\")\n",
    "            print()\n",
    "        \n",
    "        if done:\n",
    "            if verbose:\n",
    "                print(f\"Episode ended after {step+1} steps\")\n",
    "            break\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"ðŸ Total reward: {total_reward:.3f}\")\n",
    "        print(f\" Average reward per step: {total_reward/len(rewards_received):.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'actions': actions_taken,\n",
    "        'rewards': rewards_received,\n",
    "        'total_reward': total_reward\n",
    "    }\n",
    "\n",
    "# Run random episode\n",
    "random_results = run_random_episode(env, max_steps=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Custom Action Sequences\n",
    "\n",
    "Now let's run some predefined action sequences to see how the system responds to specific analysis patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_actions(env, action_vectors, description=\"Custom Actions\"):\n",
    "    \"\"\"Run a sequence of predefined actions\"\"\"\n",
    "    \n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    results = []\n",
    "    \n",
    "    print(f\" {description.upper()}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, action_vec in enumerate(action_vectors):\n",
    "        action = np.array(action_vec, dtype=np.float32)\n",
    "        \n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        print(f\"Action {i+1}: {action_to_description(action)}\")\n",
    "        print(f\"   Vector: {action_vec}\")\n",
    "        print(f\"   Reward: {reward:.3f}\")\n",
    "        \n",
    "        # Detailed reward breakdown\n",
    "        if 'reward_info' in info:\n",
    "            components = info['reward_info']\n",
    "            print(f\"   Components:\")\n",
    "            for k, v in components.items():\n",
    "                if isinstance(v, (int, float)) and k in ['diversity', 'interestingness', 'humanity']:\n",
    "                    print(f\"      {k}: {v:.3f}\")\n",
    "        print()\n",
    "        \n",
    "        results.append({\n",
    "            'action': action_vec,\n",
    "            'reward': reward,\n",
    "            'info': info\n",
    "        })\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Episode ended after {i+1} actions\")\n",
    "            break\n",
    "    \n",
    "    print(f\"ðŸ Total reward: {total_reward:.3f}\")\n",
    "    print(f\" Average reward: {total_reward/len(results):.3f}\")\n",
    "    \n",
    "    return results, total_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Exploration-focused Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ EXPLORATION-FOCUSED ANALYSIS:\n",
      "============================================================\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Action 1: ðŸ” Filter data by 'eth_dst'\n",
      "   Vector: [1, 2, 0, 0, 0, 0]\n",
      "   Reward: 3.598\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 1.129\n",
      "      humanity: -0.440\n",
      "\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Action 2: ðŸ“Š Group data by 'eth_dst'\n",
      "   Vector: [2, 2, 0, 0, 0, 0]\n",
      "   Reward: -3.000\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 0.000\n",
      "      humanity: -2.000\n",
      "\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.999565\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.999565\n",
      "ðŸŽ¯ Snorkel humanity: -0.999565\n",
      "Action 3: ðŸ”™ Go back to previous view\n",
      "   Vector: [0, 0, 0, 0, 0, 0]\n",
      "   Reward: -1.999\n",
      "   Components:\n",
      "      diversity: 0.000\n",
      "      interestingness: 0.000\n",
      "      humanity: -1.000\n",
      "\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.999565\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.999565\n",
      "ðŸŽ¯ Snorkel humanity: -0.999565\n",
      "Action 4: ðŸ” Filter data by 'tcp_srcport'\n",
      "   Vector: [1, 5, 0, 0, 0, 0]\n",
      "   Reward: 2.846\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 1.235\n",
      "      humanity: -0.750\n",
      "\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Action 5: ðŸ“Š Group data by 'tcp_srcport'\n",
      "   Vector: [2, 5, 0, 0, 0, 0]\n",
      "   Reward: -3.000\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 0.000\n",
      "      humanity: -2.000\n",
      "\n",
      "ðŸ Total reward: -1.555\n",
      "ðŸ“Š Average reward: -0.311\n"
     ]
    }
   ],
   "source": [
    "# Exploration pattern: Filter first, then group\n",
    "exploration_actions = [\n",
    "    [1, 2, 0, 0, 0, 0],  # Filter by column 2\n",
    "    [2, 2, 0, 0, 0, 0],  # Group by column 2 \n",
    "    [0, 0, 0, 0, 0, 0],  # Back to compare\n",
    "    [1, 5, 0, 0, 0, 0],  # Filter by column 5\n",
    "    [2, 5, 0, 0, 0, 0],  # Group by column 5\n",
    "]\n",
    "\n",
    "exploration_results, exploration_reward = run_custom_actions(\n",
    "    env, exploration_actions, \"Exploration-focused Analysis\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Group-first Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ GROUP-FIRST ANALYSIS:\n",
      "============================================================\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.001, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.001, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.998391\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.998391\n",
      "ðŸŽ¯ Snorkel humanity: -0.998391\n",
      "Action 1: ðŸ“Š Group data by 'column_9'\n",
      "   Vector: [2, 9, 0, 0, 0, 0]\n",
      "   Reward: 4.344\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 1.571\n",
      "      humanity: -0.198\n",
      "\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Action 2: ðŸ“Š Group data by 'highest_layer'\n",
      "   Vector: [2, 7, 0, 0, 0, 0]\n",
      "   Reward: 1.670\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 0.135\n",
      "      humanity: -0.400\n",
      "\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”„ BACK ACTION: humanity rewards only\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.000, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.999565\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.999565\n",
      "ðŸŽ¯ Snorkel humanity: -0.999565\n",
      "Action 3: ðŸ”™ Go back to previous view\n",
      "   Vector: [0, 0, 0, 0, 0, 0]\n",
      "   Reward: -1.999\n",
      "   Components:\n",
      "      diversity: 0.000\n",
      "      interestingness: 0.000\n",
      "      humanity: -1.000\n",
      "\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.002, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.002, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=-0.995058\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=-0.995058\n",
      "ðŸŽ¯ Snorkel humanity: -0.995058\n",
      "Action 4: ðŸ” Filter data by 'column_9'\n",
      "   Vector: [1, 9, 0, 0, 0, 0]\n",
      "   Reward: 2.605\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 0.622\n",
      "      humanity: -0.095\n",
      "\n",
      "ðŸ”§ Rule-based humanity coefficient applied: 1.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ Diversity coefficient applied (main calc): 2.0\n",
      "ðŸŽ¯ Using REAL LabelModel.predict_proba() on (1, 51) matrix\n",
      "âœ… Real Snorkel predictions: mean=0.500, std=0.000\n",
      "ðŸ”§ BEFORE coeff: r_snorkel_humanity=0.000000\n",
      "ðŸ”§ Using current humanity_coeff: 1.0\n",
      "ðŸ”§ AFTER coeff: r_snorkel_humanity=0.000000\n",
      "ðŸŽ¯ Snorkel humanity: 0.000000\n",
      "Action 5: ðŸ“Š Group data by 'info_line'\n",
      "   Vector: [2, 8, 0, 0, 0, 0]\n",
      "   Reward: 0.309\n",
      "   Components:\n",
      "      diversity: 2.000\n",
      "      interestingness: 0.654\n",
      "      humanity: -2.000\n",
      "\n",
      "ðŸ Total reward: 6.929\n",
      "ðŸ“Š Average reward: 1.386\n"
     ]
    }
   ],
   "source": [
    "# Group-first pattern: Start with high-level aggregations\n",
    "group_first_actions = [\n",
    "    [2, 9, 0, 0, 0, 0],  # Group by column 9 (airline for flights)\n",
    "    [2, 7, 0, 0, 0, 0],  # Group by column 7 (origin_airport)\n",
    "    [0, 0, 0, 0, 0, 0],  # Back to compare\n",
    "    [1, 9, 0, 0, 0, 0],  # Filter by column 9\n",
    "    [2, 8, 0, 0, 0, 0],  # Group by column 8 (destination)\n",
    "]\n",
    "\n",
    "group_results, group_reward = run_custom_actions(\n",
    "    env, group_first_actions, \"Group-first Analysis\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Results Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š STRATEGY COMPARISON:\n",
      "========================================\n",
      "Random                 -5.193\n",
      "Exploration-focused    -1.555\n",
      "Group-first             6.929\n",
      "\n",
      "ðŸ† Best performing strategy: Group-first (6.929)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare different strategies\n",
    "strategies = {\n",
    "    'Random': random_results['total_reward'],\n",
    "    'Exploration-focused': exploration_reward,\n",
    "    'Group-first': group_reward,\n",
    "}\n",
    "\n",
    "print(\" STRATEGY COMPARISON:\")\n",
    "print(\"=\" * 40)\n",
    "for strategy, reward in strategies.items():\n",
    "    print(f\"{strategy:20} {reward:8.3f}\")\n",
    "\n",
    "# Find best strategy\n",
    "best_strategy = max(strategies.keys(), key=lambda k: strategies[k])\n",
    "print(f\"\\n Best performing strategy: {best_strategy} ({strategies[best_strategy]:.3f})\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(strategies.keys(), strategies.values())\n",
    "plt.title('ATENA-TF Strategy Comparison')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Key Insights and Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ† KEY INSIGHTS FROM ATENA-TF:\n",
      "==================================================\n",
      "ðŸ“Š Environment Configuration:\n",
      "   Schema: NETWORKING\n",
      "   Max steps per episode: 12\n",
      "   Reward coefficients:\n",
      "      Diversity: 2.0\n",
      "      Humanity: 1.0\n",
      "      Interestingness KL: 1.5\n",
      "      Interestingness Compaction: 2.0\n",
      "\n",
      "ðŸŽ¯ What We Learned:\n",
      "   â€¢ ATENA-TF successfully replicates the original ATENA environment\n",
      "   â€¢ Multi-component reward system works: diversity + interestingness + humanity\n",
      "   â€¢ Different analysis strategies yield different rewards\n",
      "   â€¢ The system can distinguish between good and poor data exploration choices\n",
      "\n",
      "ðŸš€ Next Steps:\n",
      "   â€¢ Train PPO agents with: run_full_training.py\n",
      "   â€¢ Analyze results with: analyze_training_results.py\n",
      "   â€¢ Try different datasets: change cfg.schema to 'FLIGHTS' or 'NETWORKING'\n",
      "   â€¢ Experiment with reward coefficients in Configuration/config.py\n",
      "   â€¢ Compare with original ATENA-master results\n",
      "\n",
      "ðŸ“š Available Tools:\n",
      "   â€¢ Enhanced environment: gym_atena/envs/enhanced_atena_env.py\n",
      "   â€¢ PPO agent: models/ppo/agent.py\n",
      "   â€¢ Training system: training/enhanced_trainer.py\n",
      "   â€¢ Analysis tools: simple_action_analysis.py\n",
      "\n",
      "ðŸŽ‰ CONGRATULATIONS!\n",
      "You've successfully explored ATENA-TensorFlow!\n",
      "The system is ready for data analysis and agent training.\n"
     ]
    }
   ],
   "source": [
    "print(\" KEY INSIGHTS FROM ATENA-TF:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display configuration\n",
    "print(f\" Environment Configuration:\")\n",
    "print(f\"   Schema: {cfg.schema}\")\n",
    "print(f\"   Max steps per episode: {cfg.MAX_NUM_OF_STEPS}\")\n",
    "print(f\"   Reward coefficients:\")\n",
    "print(f\"      Diversity: {cfg.diversity_coeff}\")\n",
    "print(f\"      Humanity: {cfg.humanity_coeff}\")\n",
    "print(f\"      Interestingness KL: {cfg.kl_coeff}\")\n",
    "print(f\"      Interestingness Compaction: {cfg.compaction_coeff}\")\n",
    "\n",
    "print(f\"\\n What We Learned:\")\n",
    "print(f\"   â€¢ ATENA-TF successfully replicates the original ATENA environment\")\n",
    "print(f\"   â€¢ Multi-component reward system works: diversity + interestingness + humanity\")\n",
    "print(f\"   â€¢ Different analysis strategies yield different rewards\")\n",
    "print(f\"   â€¢ The system can distinguish between good and poor data exploration choices\")\n",
    "\n",
    "print(f\"\\n Next Steps:\")\n",
    "print(f\"   â€¢ Train PPO agents with: run_full_training.py\")\n",
    "print(f\"   â€¢ Analyze results with: analyze_training_results.py\")\n",
    "print(f\"   â€¢ Try different datasets: change cfg.schema to 'FLIGHTS' or 'NETWORKING'\")\n",
    "print(f\"   â€¢ Experiment with reward coefficients in Configuration/config.py\")\n",
    "print(f\"   â€¢ Compare with original ATENA-master results\")\n",
    "\n",
    "print(f\"\\n Available Tools:\")\n",
    "print(f\"   â€¢ Enhanced environment: gym_atena/envs/enhanced_atena_env.py\")\n",
    "print(f\"   â€¢ PPO agent: models/ppo/agent.py\")\n",
    "print(f\"   â€¢ Training system: training/enhanced_trainer.py\")\n",
    "print(f\"   â€¢ Analysis tools: simple_action_analysis.py\")\n",
    "\n",
    "print(f\"\\n CONGRATULATIONS!\")\n",
    "print(f\"You've successfully explored ATENA-TensorFlow!\")\n",
    "print(f\"The system is ready for data analysis and agent training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Trained Model Results\n",
    "\n",
    "Now let's see what our trained TensorFlow model actually learned during training!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  No training results found. Run 'run_full_training.py' first!\n"
     ]
    }
   ],
   "source": [
    "# Load training results from our actual trained model\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Find the most recent training results\n",
    "results_pattern = \"results/flight_training_*/final_results.json\"\n",
    "result_files = glob.glob(results_pattern)\n",
    "\n",
    "if result_files:\n",
    "    # Get the most recent results\n",
    "    latest_results_file = max(result_files, key=lambda x: os.path.getmtime(x))\n",
    "    results_dir = os.path.dirname(latest_results_file)\n",
    "    \n",
    "    print(f\" LOADING TRAINED MODEL RESULTS:\")\n",
    "    print(f\" From: {results_dir}\")\n",
    "    print()\n",
    "    \n",
    "    with open(latest_results_file, 'r') as f:\n",
    "        training_results = json.load(f)\n",
    "    \n",
    "    # Display key training statistics\n",
    "    print(f\" TRAINING SUMMARY:\")\n",
    "    print(f\"   Total episodes: {training_results['total_episodes']}\")\n",
    "    print(f\"   Total steps: {training_results['total_steps']}\")\n",
    "    print(f\"   Average reward: {training_results['average_reward']:.3f}\")\n",
    "    print(f\"   Final recent average: {training_results['final_recent_average']:.3f}\")\n",
    "    \n",
    "    # Show learning progress\n",
    "    improvement = training_results['final_recent_average'] - training_results['average_reward']\n",
    "    print(f\"   Learning improvement: {improvement:+.3f} {'' if improvement > 0 else ''}\")\n",
    "    \n",
    "else:\n",
    "    print(\"  No training results found. Run 'run_full_training.py' first!\")\n",
    "    training_results = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_results:\n",
    "    print(f\"\\n WHAT THE TRAINED MODEL LEARNED:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Action distribution from training\n",
    "    action_dist = training_results['action_types_distribution']\n",
    "    total_actions = sum(action_dist.values())\n",
    "    \n",
    "    print(f\"ðŸ“‹ Action preferences during training:\")\n",
    "    action_names = {\n",
    "        'back': 'ðŸ”™ Back (navigation)',\n",
    "        'filter': ' Filter (exploration)', \n",
    "        'group': ' Group (aggregation)',\n",
    "        'unknown': 'â“ Unknown'\n",
    "    }\n",
    "    \n",
    "    for action_type, count in action_dist.items():\n",
    "        percentage = (count / total_actions) * 100\n",
    "        action_name = action_names.get(action_type, action_type)\n",
    "        print(f\"   {action_name}: {count:4d} times ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Learning insights\n",
    "    print(f\"\\nðŸ§  LEARNING INSIGHTS:\")\n",
    "    if action_dist.get('back', 0) > total_actions * 0.5:\n",
    "        print(f\"   â€¢ Model is THOROUGH: Uses {action_dist.get('back', 0)/total_actions*100:.1f}% navigation\")\n",
    "        print(f\"   â€¢ Strategy: Careful exploration with lots of comparison\")\n",
    "    \n",
    "    if action_dist.get('filter', 0) > action_dist.get('group', 0):\n",
    "        print(f\"   â€¢ Model prefers EXPLORATION over aggregation\")\n",
    "        print(f\"   â€¢ Pattern: Filter first ({action_dist.get('filter', 0)} times), then group ({action_dist.get('group', 0)} times)\")\n",
    "    \n",
    "    # Reward components analysis\n",
    "    if 'reward_summary' in training_results:\n",
    "        rewards = training_results['reward_summary']\n",
    "        print(f\"\\nðŸ’° REWARD COMPONENT ANALYSIS:\")\n",
    "        print(f\"   Average diversity reward: {rewards.get('avg_diversity', 0):.3f}\")\n",
    "        print(f\"   Average interestingness: {rewards.get('avg_interestingness', 0):.3f}\")\n",
    "        print(f\"   Average humanity reward: {rewards.get('avg_humanity', 0):.3f}\")\n",
    "        \n",
    "        if rewards.get('avg_diversity', 0) > 0.15:\n",
    "            print(f\"    Good diversity - model tries varied actions\")\n",
    "        if rewards.get('avg_interestingness', 0) > 0:\n",
    "            print(f\"    Positive interestingness - finds meaningful patterns\")\n",
    "        if rewards.get('avg_humanity', 0) >= 0:\n",
    "            print(f\"    Human-like behavior - follows good analysis practices\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what specific actions the trained model learned to prefer\n",
    "if training_results and os.path.exists(results_dir):\n",
    "    session_log_file = os.path.join(results_dir, \"session_log.txt\")\n",
    "    \n",
    "    if os.path.exists(session_log_file):\n",
    "        print(f\"\\n TRAINED MODEL'S COLUMN PREFERENCES:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Parse the session log to find column preferences\n",
    "        actions_taken = {}\n",
    "        \n",
    "        with open(session_log_file, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith('Filter on Column'):\n",
    "                    if \"'\" in line:\n",
    "                        try:\n",
    "                            column = line.split(\"'\")[1]\n",
    "                            action_key = f\"Filter-{column}\"\n",
    "                            actions_taken[action_key] = actions_taken.get(action_key, 0) + 1\n",
    "                        except:\n",
    "                            pass\n",
    "                elif line.startswith('Group on Column'):\n",
    "                    if \"'\" in line:\n",
    "                        try:\n",
    "                            column = line.split(\"'\")[1]\n",
    "                            action_key = f\"Group-{column}\"\n",
    "                            actions_taken[action_key] = actions_taken.get(action_key, 0) + 1\n",
    "                        except:\n",
    "                            pass\n",
    "        \n",
    "        if actions_taken:\n",
    "            # Sort by frequency\n",
    "            sorted_actions = sorted(actions_taken.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            print(f\" TOP LEARNED ACTIONS:\")\n",
    "            for action, count in sorted_actions[:10]:\n",
    "                if 'Filter-' in action:\n",
    "                    column = action.replace('Filter-', '')\n",
    "                    print(f\"    Filter by '{column}': {count} times\")\n",
    "                elif 'Group-' in action:\n",
    "                    column = action.replace('Group-', '')\n",
    "                    print(f\"    Group by '{column}': {count} times\")\n",
    "            \n",
    "            # Extract most popular columns\n",
    "            filter_columns = {}\n",
    "            group_columns = {}\n",
    "            \n",
    "            for action, count in actions_taken.items():\n",
    "                if action.startswith('Filter-'):\n",
    "                    column = action.replace('Filter-', '')\n",
    "                    filter_columns[column] = count\n",
    "                elif action.startswith('Group-'):\n",
    "                    column = action.replace('Group-', '')\n",
    "                    group_columns[column] = count\n",
    "            \n",
    "            print(f\"\\n MODEL'S RECOMMENDED WORKFLOW:\")\n",
    "            print(f\"Based on {training_results['total_steps']} actions during training:\")\n",
    "            print()\n",
    "            \n",
    "            if filter_columns:\n",
    "                top_filter = max(filter_columns.items(), key=lambda x: x[1])\n",
    "                print(f\"1ï¸âƒ£ START with filtering by '{top_filter[0]}'\")\n",
    "                print(f\"   (Model used this {top_filter[1]} times)\")\n",
    "            \n",
    "            if group_columns:\n",
    "                top_group = max(group_columns.items(), key=lambda x: x[1])\n",
    "                print(f\"2ï¸âƒ£ THEN group by '{top_group[0]}'\")\n",
    "                print(f\"   (Model used this {top_group[1]} times)\")\n",
    "            \n",
    "            back_percentage = action_dist.get('back', 0) / total_actions * 100\n",
    "            print(f\"3ï¸âƒ£ NAVIGATE back frequently ({back_percentage:.1f}% of actions)\")\n",
    "            print(f\"   (Model is thorough and compares different views)\")\n",
    "            \n",
    "            print(f\"\\n PRACTICAL RECOMMENDATION:\")\n",
    "            if filter_columns and group_columns:\n",
    "                print(f\"   For best results, follow this pattern:\")\n",
    "                print(f\"   Filter â†’ Back â†’ Group â†’ Back â†’ Repeat\")\n",
    "                print(f\"   Focus on columns: {', '.join(list(filter_columns.keys())[:3])}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\n  Session log not found. Detailed action analysis not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¥Š Trained Model vs Random Agent Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_results:\n",
    "    print(f\"ðŸ¥Š TRAINED MODEL vs RANDOM AGENT:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Compare performance\n",
    "    trained_avg_reward = training_results['average_reward']\n",
    "    trained_final_avg = training_results['final_recent_average']\n",
    "    random_avg_reward = random_results['total_reward'] / len(random_results['rewards'])\n",
    "    \n",
    "    print(f\" PERFORMANCE COMPARISON:\")\n",
    "    print(f\"   Random Agent:\")\n",
    "    print(f\"      Average reward per step: {random_avg_reward:.3f}\")\n",
    "    print(f\"      Strategy: Completely random actions\")\n",
    "    print()\n",
    "    print(f\"   Trained Model (Early Training):\")\n",
    "    print(f\"      Average reward per step: {trained_avg_reward:.3f}\")\n",
    "    print(f\"      Improvement over random: {trained_avg_reward - random_avg_reward:+.3f}\")\n",
    "    print()\n",
    "    print(f\"   Trained Model (Final Episodes):\")\n",
    "    print(f\"      Average reward per step: {trained_final_avg:.3f}\")\n",
    "    print(f\"      Total improvement: {trained_final_avg - random_avg_reward:+.3f}\")\n",
    "    \n",
    "    # Learning assessment\n",
    "    if trained_final_avg > random_avg_reward:\n",
    "        improvement_percentage = ((trained_final_avg - random_avg_reward) / abs(random_avg_reward)) * 100\n",
    "        print(f\"    SUCCESS: Model learned! {improvement_percentage:+.1f}% better than random\")\n",
    "    else:\n",
    "        print(f\"     Model still learning - performance similar to random\")\n",
    "    \n",
    "    print(f\"\\nðŸ§  WHAT TRAINING ACHIEVED:\")\n",
    "    \n",
    "    # Compare action strategies\n",
    "    random_actions = {}\n",
    "    for action in random_results['actions']:\n",
    "        action_type = int(action[0])\n",
    "        action_name = {0: 'Back', 1: 'Filter', 2: 'Group'}.get(action_type, 'Unknown')\n",
    "        random_actions[action_name] = random_actions.get(action_name, 0) + 1\n",
    "    \n",
    "    trained_actions = training_results['action_types_distribution']\n",
    "    \n",
    "    print(f\"   Strategy Comparison:\")\n",
    "    print(f\"   {'Action':<12} {'Random':<10} {'Trained':<10} {'Learning'}\")\n",
    "    print(f\"   {'-'*12} {'-'*10} {'-'*10} {'-'*20}\")\n",
    "    \n",
    "    for action_type in ['back', 'filter', 'group']:\n",
    "        random_count = random_actions.get(action_type.title(), 0)\n",
    "        trained_count = trained_actions.get(action_type, 0)\n",
    "        \n",
    "        random_pct = (random_count / len(random_results['actions'])) * 100 if random_results['actions'] else 0\n",
    "        trained_pct = (trained_count / sum(trained_actions.values())) * 100 if trained_actions else 0\n",
    "        \n",
    "        learning_indicator = \" More focused\" if trained_pct > random_pct * 1.2 else \" Less used\" if trained_pct < random_pct * 0.8 else \"âž¡ï¸  Similar\"\n",
    "        \n",
    "        print(f\"   {action_type.title():<12} {random_pct:8.1f}% {trained_pct:8.1f}% {learning_indicator}\")\n",
    "    \n",
    "    print(f\"\\n KEY INSIGHTS:\")\n",
    "    if trained_actions.get('filter', 0) > trained_actions.get('group', 0):\n",
    "        print(f\"   â€¢ Model learned to EXPLORE first (filter > group)\")\n",
    "    if trained_actions.get('back', 0) > sum(trained_actions.values()) * 0.5:\n",
    "        print(f\"   â€¢ Model learned to be THOROUGH (lots of navigation)\")\n",
    "    print(f\"   â€¢ Model developed SPECIFIC preferences for certain columns\")\n",
    "    print(f\"   â€¢ Training shows clear LEARNING PROGRESSION over time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Run training first to see trained model comparison\n"
     ]
    }
   ],
   "source": [
    "# Enhanced strategy comparison including trained model\n",
    "if training_results:\n",
    "    enhanced_strategies = {\n",
    "        'Random': random_results['total_reward'],\n",
    "        'Exploration-focused': exploration_reward,\n",
    "        'Group-first': group_reward,\n",
    "        'Trained Model (Avg)': trained_avg_reward * 8,  # Scale to episode length\n",
    "        'Trained Model (Final)': trained_final_avg * 8,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n ENHANCED STRATEGY COMPARISON:\")\n",
    "    print(\"=\" * 60)\n",
    "    for strategy, reward in enhanced_strategies.items():\n",
    "        print(f\"{strategy:25} {reward:8.3f}\")\n",
    "    \n",
    "    # Find best strategy\n",
    "    best_strategy = max(enhanced_strategies.keys(), key=lambda k: enhanced_strategies[k])\n",
    "    print(f\"\\n Best performing: {best_strategy} ({enhanced_strategies[best_strategy]:.3f})\")\n",
    "    \n",
    "    # Visualize enhanced comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Color code bars\n",
    "    colors = ['lightblue', 'orange', 'green', 'red', 'darkred']\n",
    "    bars = plt.bar(enhanced_strategies.keys(), enhanced_strategies.values(), color=colors)\n",
    "    \n",
    "    plt.title('ATENA-TF: All Strategies Comparison (Including Trained Model)')\n",
    "    plt.ylabel('Total Reward per Episode')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight the trained model bars\n",
    "    bars[-2].set_edgecolor('black')\n",
    "    bars[-2].set_linewidth(2)\n",
    "    bars[-1].set_edgecolor('black') \n",
    "    bars[-1].set_linewidth(3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\" The trained model shows the learning curve from average to final performance!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"  Run training first to see trained model comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Final Results and Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ† COMPREHENSIVE ATENA-TF ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "ðŸŽ¯ ENVIRONMENT READY:\n",
      "   âœ… ATENA-TF environment set up successfully\n",
      "   âœ… Reward system working with all components\n",
      "   âœ… Different analysis strategies tested\n",
      "   âš ï¸  Run 'run_full_training.py' to train your own agent!\n",
      "\n",
      "ðŸš€ NEXT STEPS:\n",
      "   â€¢ Experiment with different reward coefficients in config.py\n",
      "   â€¢ Try different schemas (FLIGHTS vs NETWORKING)\n",
      "   â€¢ Train for more episodes to see further improvement\n",
      "   â€¢ Compare with human expert analysis patterns\n",
      "   â€¢ Use the system for real data exploration tasks\n",
      "\n",
      "ðŸ“š TOOLS AVAILABLE:\n",
      "   â€¢ run_full_training.py - Train new agents\n",
      "   â€¢ analyze_training_results.py - Analyze performance\n",
      "   â€¢ simple_action_analysis.py - Understand behavior\n",
      "   â€¢ compare_with_master.py - Compare with original ATENA\n",
      "\n",
      "ðŸŽ‰ CONGRATULATIONS!\n",
      "You have successfully explored the complete ATENA-TensorFlow system!\n",
      "ðŸ¤– Ready for intelligent data analysis and reinforcement learning!\n"
     ]
    }
   ],
   "source": [
    "print(\" COMPREHENSIVE ATENA-TF ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if training_results:\n",
    "    print(f\" WHAT WE ACHIEVED:\")\n",
    "    print(f\"    Successfully replicated ATENA environment in TensorFlow\")\n",
    "    print(f\"    Trained PPO agent for {training_results['total_episodes']} episodes\")\n",
    "    print(f\"    Demonstrated learning progression and strategy development\")\n",
    "    print(f\"    Identified specific column preferences and workflows\")\n",
    "    print(f\"    Achieved measurable improvement over random actions\")\n",
    "    \n",
    "    print(f\"\\n KEY FINDINGS:\")\n",
    "    if 'action_types_distribution' in training_results:\n",
    "        action_dist = training_results['action_types_distribution']\n",
    "        total = sum(action_dist.values())\n",
    "        print(f\"   â€¢ Trained model uses {action_dist.get('back', 0)/total*100:.1f}% navigation (thorough)\")\n",
    "        print(f\"   â€¢ Prefers exploration: {action_dist.get('filter', 0)} filters vs {action_dist.get('group', 0)} groups\")\n",
    "        print(f\"   â€¢ Shows clear learning: final performance > average performance\")\n",
    "    \n",
    "    print(f\"\\n PRACTICAL USER RECOMMENDATIONS:\")\n",
    "    print(f\"   Based on {training_results['total_steps']} trained actions:\")\n",
    "    print(f\"   1ï¸âƒ£ START with filtering to explore data subsets\")\n",
    "    print(f\"   2ï¸âƒ£ USE navigation frequently to compare different views\") \n",
    "    print(f\"   3ï¸âƒ£ GROUP by the same columns you filtered for consistency\")\n",
    "    print(f\"   4ï¸âƒ£ FOCUS on key identifier columns (packet_number, eth_dst, etc.)\")\n",
    "    print(f\"   5ï¸âƒ£ FOLLOW the pattern: Filter â†’ Back â†’ Group â†’ Back â†’ Repeat\")\n",
    "\n",
    "else:\n",
    "    print(f\" ENVIRONMENT READY:\")\n",
    "    print(f\"    ATENA-TF environment set up successfully\")\n",
    "    print(f\"    Reward system working with all components\")\n",
    "    print(f\"    Different analysis strategies tested\")\n",
    "    print(f\"     Run 'run_full_training.py' to train your own agent!\")\n",
    "\n",
    "print(f\"\\n NEXT STEPS:\")\n",
    "print(f\"   â€¢ Experiment with different reward coefficients in config.py\")\n",
    "print(f\"   â€¢ Try different schemas (FLIGHTS vs NETWORKING)\")\n",
    "print(f\"   â€¢ Train for more episodes to see further improvement\")\n",
    "print(f\"   â€¢ Compare with human expert analysis patterns\")\n",
    "print(f\"   â€¢ Use the system for real data exploration tasks\")\n",
    "\n",
    "print(f\"\\n TOOLS AVAILABLE:\")\n",
    "print(f\"   â€¢ run_full_training.py - Train new agents\")\n",
    "print(f\"   â€¢ analyze_training_results.py - Analyze performance\")\n",
    "print(f\"   â€¢ simple_action_analysis.py - Understand behavior\")\n",
    "print(f\"   â€¢ compare_with_master.py - Compare with original ATENA\")\n",
    "\n",
    "print(f\"\\n CONGRATULATIONS!\")\n",
    "print(f\"You have successfully explored the complete ATENA-TensorFlow system!\")\n",
    "print(f\" Ready for intelligent data analysis and reinforcement learning!\")\n",
    "\n",
    "if training_results:\n",
    "    print(f\"\\n FINAL SUCCESS METRIC:\")\n",
    "    improvement = training_results['final_recent_average'] - training_results['average_reward']\n",
    "    print(f\"   Learning Improvement: {improvement:+.3f} reward points\")\n",
    "    if improvement > 0:\n",
    "        print(f\"   ðŸŽŠ SUCCESS: Model learned effective data analysis strategies!\")\n",
    "    else:\n",
    "        print(f\"    Model showing progress - continue training for better results!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}